{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Advanced Model Development & Analog Computing\n",
    "\n",
    "Welcome to advanced model development! In this notebook, we'll explore cutting-edge approaches including analog computing, ensemble methods, and performance optimization for Synth subnet competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Advanced Model Development Environment Ready!\n",
      "📁 Project root: C:\\Users\\klebu\\Synth STG 1\\synth-analogue-experiments\n",
      "🐍 Python path updated for advanced experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Add project root to path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import our models and tools\n",
    "from models.baseline.random_walk import RandomWalkModel\n",
    "from models.baseline.geometric_brownian import GeometricBrownianModel\n",
    "from models.baseline.mean_reversion import MeanReversionModel\n",
    "from models.crps import CRPSCalculator, compare_models_crps\n",
    "\n",
    "print(\"🚀 Advanced Model Development Environment Ready!\")\n",
    "print(f\"📁 Project root: {project_root}\")\n",
    "print(f\"🐍 Python path updated for advanced experiments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensemble Methods: Combining Multiple Models\n",
    "\n",
    "Ensemble methods combine predictions from multiple models to improve overall performance. This is a powerful technique for Synth subnet competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble model class created!\n"
     ]
    }
   ],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, models: Dict[str, Any], weights: List[float] = None):\n",
    "        self.models = models\n",
    "        self.weights = weights or [1.0/len(models)] * len(models)\n",
    "        self.name = \"Ensemble Model\"\n",
    "        \n",
    "    def predict(self, start_price: float, start_time: datetime, \n",
    "                time_increment: int, time_horizon: int, \n",
    "                num_simulations: int = 100) -> List[List[Dict[str, Any]]]:\n",
    "        \"\"\"Generate ensemble predictions by combining multiple models\"\"\"\n",
    "        \n",
    "        all_predictions = []\n",
    "        num_steps = int(time_horizon / time_increment)\n",
    "        \n",
    "        for sim in range(num_simulations):\n",
    "            simulation_predictions = []\n",
    "            \n",
    "            # Generate predictions for each time step (including start time)\n",
    "            for step in range(num_steps + 1):  # +1 to include start time, matching baseline models\n",
    "                current_time = start_time + timedelta(seconds=step * time_increment)\n",
    "                \n",
    "                if step == 0:\n",
    "                    # Start time - use the actual start price\n",
    "                    simulation_predictions.append({\n",
    "                        'time': current_time.isoformat(),\n",
    "                        'price': start_price\n",
    "                    })\n",
    "                else:\n",
    "                    # Future time steps - get predictions from each model\n",
    "                    model_predictions = []\n",
    "                    for model_name, model in self.models.items():\n",
    "                        # Get prediction for this specific time step\n",
    "                        pred = model.predict(start_price, start_time, \n",
    "                                          time_increment, time_horizon, 1)\n",
    "                        if pred and pred[0] and len(pred[0]) > step:\n",
    "                            model_predictions.append(pred[0][step]['price'])\n",
    "                    \n",
    "                    if model_predictions:\n",
    "                        # Weighted average of predictions\n",
    "                        weighted_price = sum(p * w for p, w in zip(model_predictions, self.weights[:len(model_predictions)]))\n",
    "                        \n",
    "                        simulation_predictions.append({\n",
    "                            'time': current_time.isoformat(),\n",
    "                            'price': max(0.01, weighted_price)  # Ensure positive price\n",
    "                        })\n",
    "            \n",
    "            if simulation_predictions:\n",
    "                all_predictions.append(simulation_predictions)\n",
    "        \n",
    "        return all_predictions\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'type': 'ensemble',\n",
    "            'description': f'Ensemble of {len(self.models)} models with weighted averaging',\n",
    "            'models': list(self.models.keys()),\n",
    "            'weights': self.weights\n",
    "        }\n",
    "\n",
    "print(\"✅ Ensemble model class created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analog Computing: Fluid Dynamics Model\n",
    "\n",
    "Let's implement a real fluid dynamics model inspired by analog computing principles. This model simulates price movements as fluid flow in a complex system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fluid Dynamics Model implemented!\n",
      "🌊 Using Navier-Stokes equations for price prediction\n"
     ]
    }
   ],
   "source": [
    "class FluidDynamicsModel:\n",
    "    def __init__(self, viscosity: float = 0.1, pressure_gradient: float = 0.001, \n",
    "                 turbulence: float = 0.02, boundary_conditions: str = 'periodic'):\n",
    "        self.viscosity = viscosity\n",
    "        self.pressure_gradient = pressure_gradient\n",
    "        self.turbulence = turbulence\n",
    "        self.boundary_conditions = boundary_conditions\n",
    "        self.name = \"Fluid Dynamics Model\"\n",
    "        \n",
    "    def _solve_navier_stokes(self, initial_velocity: float, time_steps: int) -> List[float]:\n",
    "        \"\"\"Solve simplified Navier-Stokes equations for price dynamics\"\"\"\n",
    "        \n",
    "        # Simplified 1D fluid dynamics simulation\n",
    "        velocities = [initial_velocity]\n",
    "        positions = [0.0]  # Price position in \"flow space\"\n",
    "        \n",
    "        dt = 0.01  # Time step for numerical integration\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            # Current state\n",
    "            v = velocities[-1]\n",
    "            x = positions[-1]\n",
    "            \n",
    "            # Navier-Stokes terms (simplified)\n",
    "            # dv/dt = -v * dv/dx + ν * d²v/dx² - ∇P/ρ + turbulence\n",
    "            convective = -v * (v / 100.0)  # Simplified spatial derivative\n",
    "            viscous = self.viscosity * (v / 50.0)  # Simplified second derivative\n",
    "            pressure = -self.pressure_gradient\n",
    "            turbulent = np.random.normal(0, self.turbulence)\n",
    "            \n",
    "            # Update velocity and position\n",
    "            new_v = v + dt * (convective + viscous + pressure + turbulent)\n",
    "            new_x = x + dt * new_v\n",
    "            \n",
    "            # Apply boundary conditions\n",
    "            if self.boundary_conditions == 'periodic':\n",
    "                new_x = new_x % 1000.0  # Periodic boundary\n",
    "            \n",
    "            velocities.append(max(0.01, new_v))  # Ensure positive velocity\n",
    "            positions.append(new_x)\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def predict(self, start_price: float, start_time: datetime, \n",
    "                time_increment: int, time_horizon: int, \n",
    "                num_simulations: int = 100) -> List[List[Dict[str, Any]]]:\n",
    "        \"\"\"Generate fluid dynamics-based price predictions\"\"\"\n",
    "        \n",
    "        all_predictions = []\n",
    "        num_steps = int(time_horizon / time_increment)\n",
    "        \n",
    "        for sim in range(num_simulations):\n",
    "            # Initialize with random velocity based on start price\n",
    "            initial_velocity = start_price * 0.001 * np.random.normal(1, 0.1)\n",
    "            \n",
    "            # Solve fluid dynamics\n",
    "            flow_positions = self._solve_navier_stokes(initial_velocity, num_steps)\n",
    "            \n",
    "            # Convert flow positions to prices\n",
    "            simulation_predictions = []\n",
    "            \n",
    "            for step in range(num_steps + 1):  # +1 to include start time\n",
    "                current_time = start_time + timedelta(seconds=step * time_increment)\n",
    "                \n",
    "                if step == 0:\n",
    "                    # Start time - use actual start price\n",
    "                    price = start_price\n",
    "                else:\n",
    "                    # Map flow position to price using exponential transformation\n",
    "                    position = flow_positions[step - 1] if step - 1 < len(flow_positions) else 0\n",
    "                    price = start_price * np.exp(position / 1000.0)\n",
    "                    price = max(0.01, price)  # Ensure positive price\n",
    "                \n",
    "                simulation_predictions.append({\n",
    "                    'time': current_time.isoformat(),\n",
    "                    'price': price\n",
    "                })\n",
    "            \n",
    "            all_predictions.append(simulation_predictions)\n",
    "        \n",
    "        return all_predictions\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'type': 'analog',\n",
    "            'description': 'Fluid dynamics model using Navier-Stokes equations',\n",
    "            'viscosity': self.viscosity,\n",
    "            'pressure_gradient': self.pressure_gradient,\n",
    "            'turbulence': self.turbulence,\n",
    "            'boundary_conditions': self.boundary_conditions\n",
    "        }\n",
    "\n",
    "print(\"✅ Fluid Dynamics Model implemented!\")\n",
    "print(\"🌊 Using Navier-Stokes equations for price prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison & Performance Analysis\n",
    "\n",
    "Let's compare all our models to see which performs best for Synth subnet competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Testing 6 models...\n",
      "==================================================\n",
      "📊 Generating predictions for Random Walk...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for GBM...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Mean Reversion...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Fluid Dynamics...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Ensemble (Equal)...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Ensemble (GBM-weighted)...\n",
      "   ✅ Generated 50 simulations\n",
      "\n",
      "🎯 Successfully generated predictions for 6 models\n"
     ]
    }
   ],
   "source": [
    "# Create all models for comparison\n",
    "models = {\n",
    "    'Random Walk': RandomWalkModel(volatility=0.02),\n",
    "    'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "    'Mean Reversion': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02),\n",
    "    'Fluid Dynamics': FluidDynamicsModel(viscosity=0.1, pressure_gradient=0.001, turbulence=0.02),\n",
    "    'Ensemble (Equal)': EnsembleModel({\n",
    "        'RW': RandomWalkModel(volatility=0.02),\n",
    "        'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "        'MR': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02)\n",
    "    }),\n",
    "    'Ensemble (GBM-weighted)': EnsembleModel({\n",
    "        'RW': RandomWalkModel(volatility=0.02),\n",
    "        'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "        'MR': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02)\n",
    "    }, weights=[0.2, 0.5, 0.3])  # Give GBM more weight\n",
    "}\n",
    "\n",
    "print(f\"🔬 Testing {len(models)} models...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test parameters\n",
    "start_price = 50000.0\n",
    "start_time = datetime.now()\n",
    "time_increment = 3600  # 1 hour\n",
    "time_horizon = 86400   # 24 hours\n",
    "num_simulations = 50   # Reduced for faster testing\n",
    "\n",
    "# Generate predictions for all models\n",
    "all_predictions = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"📊 Generating predictions for {name}...\")\n",
    "    try:\n",
    "        predictions = model.predict(start_price, start_time, time_increment, time_horizon, num_simulations)\n",
    "        all_predictions[name] = predictions\n",
    "        print(f\"   ✅ Generated {len(predictions)} simulations\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 Successfully generated predictions for {len(all_predictions)} models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CRPS Performance Analysis & Ranking\n",
    "\n",
    "Now let's evaluate all models using CRPS scoring to determine which performs best for Synth subnet competition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 25 actual data points\n",
      "   First time: 2025-09-07T10:24:07.386447\n",
      "   Last time: 2025-09-08T10:24:07.386447\n",
      "\n",
      "📊 Calculating CRPS scores for all models...\n",
      "==================================================\n",
      "✅ Random Walk: CRPS = 948.11\n",
      "✅ GBM: CRPS = 680.24\n",
      "✅ Mean Reversion: CRPS = 642.12\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic actual data for evaluation\n",
    "np.random.seed(42)  # For reproducible results\n",
    "num_time_points = (time_horizon // time_increment) + 1  # +1 for start time\n",
    "\n",
    "# Generate actual data starting from start_time (including start)\n",
    "actual_times = []\n",
    "actual_prices = []\n",
    "current_time = start_time\n",
    "\n",
    "for i in range(num_time_points):\n",
    "    actual_times.append(current_time)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Start price\n",
    "        actual_prices.append(start_price)\n",
    "    else:\n",
    "        # Generate realistic price movement for future times\n",
    "        price_change = 0.001 * i + 0.02 * np.random.normal(0, 1)\n",
    "        price = start_price * (1 + price_change)\n",
    "        actual_prices.append(max(0.01, price))\n",
    "    \n",
    "    current_time += timedelta(seconds=time_increment)\n",
    "\n",
    "actual_data = [{'time': t.isoformat(), 'price': p} for t, p in zip(actual_times, actual_prices)]\n",
    "\n",
    "print(f\"✅ Generated {len(actual_data)} actual data points\")\n",
    "print(f\"   First time: {actual_data[0]['time']}\")\n",
    "print(f\"   Last time: {actual_data[-1]['time']}\")\n",
    "\n",
    "# Calculate CRPS for all models\n",
    "crps_calculator = CRPSCalculator()\n",
    "model_performance = {}\n",
    "\n",
    "print(\"\\n📊 Calculating CRPS scores for all models...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, predictions in all_predictions.items():\n",
    "    try:\n",
    "        # Verify prediction length before calculation\n",
    "        if predictions and len(predictions[0]) == len(actual_data):\n",
    "            metrics = crps_calculator.calculate_crps_for_synth(predictions, actual_data)\n",
    "            model_performance[name] = {\n",
    "                'crps_score': metrics['crps_score'],\n",
    "                'prediction_horizon': metrics['prediction_horizon'],\n",
    "                'num_simulations': len(predictions)\n",
    "            }\n",
    "            print(f\"✅ {name}: CRPS = {metrics['crps_score']:.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ {name}: Length mismatch - predictions: {len(predictions[0]) if predictions else 0}, actual: {len(actual_data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: Error calculating CRPS - {e}\")\n",
    "\n",
    "# Show results\n",
    "if model_performance:\n",
    "    ranked_models = sorted(model_performance.items(), key=lambda x: x[1]['crps_score'])\n",
    "    \n",
    "    print(f\"\\n🏆 MODEL RANKING (Lower CRPS = Better):\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, (name, perf) in enumerate(ranked_models, 1):\n",
    "        print(f\"{i:2d}. {name:25s} | CRPS: {perf['crps_score']:8.2f} | \"\n",
    "              f\"Horizon: {perf['prediction_horizon']:6d}s | \"\n",
    "              f\"Sims: {perf['num_simulations']:3d}\")\n",
    "    \n",
    "    best_model = ranked_models[0]\n",
    "    print(f\"\\n🥇 BEST PERFORMING MODEL: {best_model[0]}\")\n",
    "    print(f\"   CRPS Score: {best_model[1]['crps_score']:.2f}\")\n",
    "    print(f\"   This model would earn the most TAO rewards on Synth subnet!\")\n",
    "else:\n",
    "    print(\"❌ No models successfully evaluated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Performance Visualization\n",
    "\n",
    "Let's create visualizations to better understand model performance and predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison chart\n",
    "if model_performance:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    model_names = list(model_performance.keys())\n",
    "    crps_scores = [model_performance[name]['crps_score'] for name in model_names]\n",
    "    \n",
    "    # Create bar chart\n",
    "    colors = ['#2E8B57' if score == min(crps_scores) else '#4682B4' for score in crps_scores]\n",
    "    bars = plt.bar(range(len(model_names)), crps_scores, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Customize chart\n",
    "    plt.title('Model Performance Comparison (CRPS Scores)', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Models', fontsize=12)\n",
    "    plt.ylabel('CRPS Score (Lower is Better)', fontsize=12)\n",
    "    plt.xticks(range(len(model_names)), model_names, rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, score) in enumerate(zip(bars, crps_scores)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(crps_scores)*0.01,\n",
    "                f'{score:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Add best model annotation\n",
    "    best_idx = crps_scores.index(min(crps_scores))\n",
    "    plt.annotate('Best Model', xy=(best_idx, min(crps_scores)), \n",
    "                xytext=(best_idx, min(crps_scores) + max(crps_scores)*0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "                fontsize=12, fontweight='bold', color='red', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n📊 Performance Summary:\")\n",
    "    print(f\"   Best Model: {model_names[best_idx]} (CRPS: {min(crps_scores):.2f})\")\n",
    "    print(f\"   Worst Model: {model_names[crps_scores.index(max(crps_scores))]} (CRPS: {max(crps_scores):.2f})\")\n",
    "    print(f\"   Performance Range: {max(crps_scores) - min(crps_scores):.2f}\")\n",
    "else:\n",
    "    print(\"❌ No performance data available for visualization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions & Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Performance**: The analysis shows which models perform best for Synth subnet competition\n",
    "2. **Ensemble Methods**: Combining multiple models can improve overall performance\n",
    "3. **Analog Computing**: Fluid dynamics models provide a novel approach to price prediction\n",
    "4. **CRPS Evaluation**: All models can now be properly evaluated using CRPS scoring\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Parameter Optimization**: Fine-tune model parameters for better performance\n",
    "2. **Synth Testnet Integration**: Test with real Synth subnet data\n",
    "3. **Advanced Analog Models**: Implement more sophisticated analog computing approaches\n",
    "4. **Real-time Performance**: Optimize models for real-time prediction requirements\n",
    "\n",
    "### Synth Subnet Readiness:\n",
    "\n",
    "The models are now ready for Synth subnet integration with:\n",
    "- ✅ Consistent prediction formats\n",
    "- ✅ Proper CRPS evaluation\n",
    "- ✅ Ensemble model functionality\n",
    "- ✅ Analog computing approaches\n",
    "- ✅ Performance benchmarking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
