{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864475f4",
   "metadata": {},
   "source": [
    "## 1. Advanced Model Development & Analog Computing\n",
    "\n",
    "Welcome to advanced model development! In this notebook, we'll explore cutting-edge approaches including analog computing, ensemble methods, and performance optimization for Synth subnet competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bace36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Advanced Model Development Environment Ready!\n",
      "📁 Project root: C:\\Users\\klebu\\Synth STG 1\\synth-analogue-experiments\n",
      "🐍 Python path updated for advanced experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# Add project root to path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import our models and tools\n",
    "from models.baseline.random_walk import RandomWalkModel\n",
    "from models.baseline.geometric_brownian import GeometricBrownianModel\n",
    "from models.baseline.mean_reversion import MeanReversionModel\n",
    "from models.crps import CRPSCalculator, compare_models_crps\n",
    "\n",
    "print(\"🚀 Advanced Model Development Environment Ready!\")\n",
    "print(f\"📁 Project root: {project_root}\")\n",
    "print(f\"🐍 Python path updated for advanced experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02451f0",
   "metadata": {},
   "source": [
    "## 2. Ensemble Methods: Combining Multiple Models\n",
    "\n",
    "Ensemble methods combine predictions from multiple models to improve overall performance. This is a powerful technique for Synth subnet competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a69d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble model class created!\n"
     ]
    }
   ],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, models: Dict[str, Any], weights: List[float] = None):\n",
    "        self.models = models\n",
    "        self.weights = weights or [1.0/len(models)] * len(models)\n",
    "        self.name = \"Ensemble Model\"\n",
    "        \n",
    "    def predict(self, start_price: float, start_time: datetime, \n",
    "                time_increment: int, time_horizon: int, \n",
    "                num_simulations: int = 100) -> List[List[Dict[str, Any]]]:\n",
    "        \"\"\"Generate ensemble predictions by combining multiple models\"\"\"\n",
    "        \n",
    "        all_predictions = []\n",
    "        \n",
    "        for i in range(num_simulations):\n",
    "            simulation_predictions = []\n",
    "            current_time = start_time\n",
    "            \n",
    "            for _ in range(time_horizon // time_increment):\n",
    "                # Get predictions from each model\n",
    "                model_predictions = []\n",
    "                for model_name, model in self.models.items():\n",
    "                    pred = model.predict(start_price, current_time, \n",
    "                                      time_increment, time_increment, 1)\n",
    "                    if pred and pred[0]:\n",
    "                        model_predictions.append(pred[0][0]['price'])\n",
    "                \n",
    "                if model_predictions:\n",
    "                    # Weighted average of predictions\n",
    "                    weighted_price = sum(p * w for p, w in zip(model_predictions, self.weights[:len(model_predictions)]))\n",
    "                    \n",
    "                    simulation_predictions.append({\n",
    "                        'time': current_time.isoformat(),\n",
    "                        'price': max(0.01, weighted_price)  # Ensure positive price\n",
    "                    })\n",
    "                \n",
    "                current_time += timedelta(seconds=time_increment)\n",
    "            \n",
    "            if simulation_predictions:\n",
    "                all_predictions.append(simulation_predictions)\n",
    "        \n",
    "        return all_predictions\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'type': 'ensemble',\n",
    "            'description': f'Ensemble of {len(self.models)} models with weighted averaging',\n",
    "            'models': list(self.models.keys()),\n",
    "            'weights': self.weights\n",
    "        }\n",
    "\n",
    "print(\"✅ Ensemble model class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ede6bd4",
   "metadata": {},
   "source": [
    "## 3. Analog Computing: Fluid Dynamics Model\n",
    "\n",
    "Let's implement a real fluid dynamics model inspired by analog computing principles. This model simulates price movements as fluid flow in a complex system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7048788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fluid Dynamics Model implemented!\n",
      "🌊 Using Navier-Stokes equations for price prediction\n"
     ]
    }
   ],
   "source": [
    "class FluidDynamicsModel:\n",
    "    def __init__(self, viscosity: float = 0.1, pressure_gradient: float = 0.001, \n",
    "                 turbulence: float = 0.02, boundary_conditions: str = 'periodic'):\n",
    "        self.viscosity = viscosity\n",
    "        self.pressure_gradient = pressure_gradient\n",
    "        self.turbulence = turbulence\n",
    "        self.boundary_conditions = boundary_conditions\n",
    "        self.name = \"Fluid Dynamics Model\"\n",
    "        \n",
    "    def _solve_navier_stokes(self, initial_velocity: float, time_steps: int) -> List[float]:\n",
    "        \"\"\"Solve simplified Navier-Stokes equations for price dynamics\"\"\"\n",
    "        \n",
    "        # Simplified 1D fluid dynamics simulation\n",
    "        velocities = [initial_velocity]\n",
    "        positions = [0.0]  # Price position in \"flow space\"\n",
    "        \n",
    "        dt = 0.01  # Time step for numerical integration\n",
    "        \n",
    "        for t in range(time_steps):\n",
    "            # Current state\n",
    "            v = velocities[-1]\n",
    "            x = positions[-1]\n",
    "            \n",
    "            # Navier-Stokes terms (simplified)\n",
    "            # dv/dt = -v * dv/dx + ν * d²v/dx² - ∇P/ρ + turbulence\n",
    "            convective = -v * (v / 100.0)  # Simplified spatial derivative\n",
    "            viscous = self.viscosity * (v / 50.0)  # Simplified second derivative\n",
    "            pressure = -self.pressure_gradient\n",
    "            turbulent = np.random.normal(0, self.turbulence)\n",
    "            \n",
    "            # Update velocity and position\n",
    "            new_v = v + dt * (convective + viscous + pressure + turbulent)\n",
    "            new_x = x + dt * new_v\n",
    "            \n",
    "            # Apply boundary conditions\n",
    "            if self.boundary_conditions == 'periodic':\n",
    "                new_x = new_x % 1000.0  # Periodic boundary\n",
    "            \n",
    "            velocities.append(max(0.01, new_v))  # Ensure positive velocity\n",
    "            positions.append(new_x)\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def predict(self, start_price: float, start_time: datetime, \n",
    "                time_increment: int, time_horizon: int, \n",
    "                num_simulations: int = 100) -> List[List[Dict[str, Any]]]:\n",
    "        \"\"\"Generate fluid dynamics-based price predictions\"\"\"\n",
    "        \n",
    "        all_predictions = []\n",
    "        time_steps = time_horizon // time_increment\n",
    "        \n",
    "        for sim in range(num_simulations):\n",
    "            # Initialize with random velocity based on start price\n",
    "            initial_velocity = start_price * 0.001 * np.random.normal(1, 0.1)\n",
    "            \n",
    "            # Solve fluid dynamics\n",
    "            flow_positions = self._solve_navier_stokes(initial_velocity, time_steps)\n",
    "            \n",
    "            # Convert flow positions to prices\n",
    "            simulation_predictions = []\n",
    "            current_time = start_time\n",
    "            \n",
    "            for i, position in enumerate(flow_positions):\n",
    "                # Map flow position to price using exponential transformation\n",
    "                price = start_price * np.exp(position / 1000.0)\n",
    "                price = max(0.01, price)  # Ensure positive price\n",
    "                \n",
    "                simulation_predictions.append({\n",
    "                    'time': current_time.isoformat(),\n",
    "                    'price': price\n",
    "                })\n",
    "                \n",
    "                current_time += timedelta(seconds=time_increment)\n",
    "            \n",
    "            all_predictions.append(simulation_predictions)\n",
    "        \n",
    "        return all_predictions\n",
    "    \n",
    "    def get_model_info(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            'name': self.name,\n",
    "            'type': 'analog',\n",
    "            'description': 'Fluid dynamics model using Navier-Stokes equations',\n",
    "            'viscosity': self.viscosity,\n",
    "            'pressure_gradient': self.pressure_gradient,\n",
    "            'turbulence': self.turbulence,\n",
    "            'boundary_conditions': self.boundary_conditions\n",
    "        }\n",
    "\n",
    "print(\"✅ Fluid Dynamics Model implemented!\")\n",
    "print(\"🌊 Using Navier-Stokes equations for price prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448457c",
   "metadata": {},
   "source": [
    "## 4. Advanced Model Comparison & Performance Analysis\n",
    "\n",
    "Let's compare our baseline models, ensemble approach, and new analog model to see which performs best for Synth subnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e611b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Testing 6 models...\n",
      "============================================================\n",
      "📊 Generating predictions for Random Walk...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for GBM...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Mean Reversion...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Fluid Dynamics...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Ensemble (Equal)...\n",
      "   ✅ Generated 50 simulations\n",
      "📊 Generating predictions for Ensemble (GBM-weighted)...\n",
      "   ✅ Generated 50 simulations\n",
      "\n",
      "🎯 Successfully generated predictions for 6 models\n"
     ]
    }
   ],
   "source": [
    "# Create all models including new ones\n",
    "models = {\n",
    "    'Random Walk': RandomWalkModel(volatility=0.02),\n",
    "    'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "    'Mean Reversion': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02),\n",
    "    'Fluid Dynamics': FluidDynamicsModel(viscosity=0.1, pressure_gradient=0.001, turbulence=0.02),\n",
    "    'Ensemble (Equal)': EnsembleModel({\n",
    "        'RW': RandomWalkModel(volatility=0.02),\n",
    "        'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "        'MR': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02)\n",
    "    }),\n",
    "    'Ensemble (GBM-weighted)': EnsembleModel({\n",
    "        'RW': RandomWalkModel(volatility=0.02),\n",
    "        'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "        'MR': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02)\n",
    "    }, weights=[0.2, 0.5, 0.3])  # Give GBM more weight\n",
    "}\n",
    "\n",
    "print(f\"🔬 Testing {len(models)} models...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test parameters\n",
    "start_price = 50000.0\n",
    "start_time = datetime.now()\n",
    "time_increment = 3600  # 1 hour\n",
    "time_horizon = 86400   # 24 hours\n",
    "num_simulations = 50   # Reduced for faster testing\n",
    "\n",
    "# Generate predictions for all models\n",
    "all_predictions = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"📊 Generating predictions for {name}...\")\n",
    "    try:\n",
    "        predictions = model.predict(start_price, start_time, time_increment, time_horizon, num_simulations)\n",
    "        all_predictions[name] = predictions\n",
    "        print(f\"   ✅ Generated {len(predictions)} simulations\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 Successfully generated predictions for {len(all_predictions)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdaf94a",
   "metadata": {},
   "source": [
    "## 5. CRPS Performance Analysis & Ranking\n",
    "\n",
    "Now let's evaluate all models using CRPS scoring to determine which performs best for Synth subnet competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012e14b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Calculating CRPS scores for all models...\n",
      "============================================================\n",
      "❌ Random Walk: Error calculating CRPS - Number of predictions (25) must match number of actual times (24)\n",
      "❌ GBM: Error calculating CRPS - Number of predictions (25) must match number of actual times (24)\n",
      "❌ Mean Reversion: Error calculating CRPS - Number of predictions (25) must match number of actual times (24)\n",
      "❌ Fluid Dynamics: Error calculating CRPS - Number of predictions (25) must match number of actual times (24)\n",
      "✅ Ensemble (Equal): CRPS = 576.17\n",
      "✅ Ensemble (GBM-weighted): CRPS = 618.70\n",
      "\n",
      "🏆 MODEL RANKING (Lower CRPS = Better):\n",
      "============================================================\n",
      " 1. Ensemble (Equal)          | CRPS:   576.17 | Horizon:  82800s | Sims:  50\n",
      " 2. Ensemble (GBM-weighted)   | CRPS:   618.70 | Horizon:  82800s | Sims:  50\n",
      "\n",
      "🥇 BEST PERFORMING MODEL: Ensemble (Equal)\n",
      "   CRPS Score: 576.17\n",
      "   This model would earn the most TAO rewards on Synth subnet!\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic actual data for evaluation\n",
    "np.random.seed(42)  # For reproducible results\n",
    "actual_times = [start_time + timedelta(seconds=i * time_increment) \n",
    "                for i in range(time_horizon // time_increment)]\n",
    "actual_prices = [start_price * (1 + 0.001 * i + 0.02 * np.random.normal(0, 1)) \n",
    "                 for i in range(len(actual_times))]\n",
    "actual_data = [{'time': t.isoformat(), 'price': max(0.01, p)} \n",
    "               for t, p in zip(actual_times, actual_prices)]\n",
    "\n",
    "# Calculate CRPS for all models\n",
    "crps_calculator = CRPSCalculator()\n",
    "model_performance = {}\n",
    "\n",
    "print(\"📊 Calculating CRPS scores for all models...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, predictions in all_predictions.items():\n",
    "    try:\n",
    "        metrics = crps_calculator.calculate_crps_for_synth(predictions, actual_data)\n",
    "        model_performance[name] = {\n",
    "            'crps_score': metrics['crps_score'],\n",
    "            'prediction_horizon': metrics['prediction_horizon'],\n",
    "            'num_simulations': len(predictions)\n",
    "        }\n",
    "        print(f\"✅ {name}: CRPS = {metrics['crps_score']:.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: Error calculating CRPS - {e}\")\n",
    "\n",
    "# Rank models by performance\n",
    "if model_performance:\n",
    "    ranked_models = sorted(model_performance.items(), key=lambda x: x[1]['crps_score'])\n",
    "    \n",
    "    print(f\"\\n🏆 MODEL RANKING (Lower CRPS = Better):\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (name, perf) in enumerate(ranked_models, 1):\n",
    "        print(f\"{i:2d}. {name:25s} | CRPS: {perf['crps_score']:8.2f} | \"\n",
    "              f\"Horizon: {perf['prediction_horizon']:6d}s | \"\n",
    "              f\"Sims: {perf['num_simulations']:3d}\")\n",
    "    \n",
    "    # Best model analysis\n",
    "    best_model = ranked_models[0]\n",
    "    print(f\"\\n🥇 BEST PERFORMING MODEL: {best_model[0]}\")\n",
    "    print(f\"   CRPS Score: {best_model[1]['crps_score']:.2f}\")\n",
    "    print(f\"   This model would earn the most TAO rewards on Synth subnet!\")\n",
    "else:\n",
    "    print(\"❌ No models successfully evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bcc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DEBUGGING PREDICTION LENGTH MISMATCH\n",
      "============================================================\n",
      "Expected time points: 24\n",
      "Time horizon: 86400 seconds\n",
      "Time increment: 3600 seconds\n",
      "\n",
      "📊 Test prediction details:\n",
      "   Number of simulations: 1\n",
      "   Number of time points: 25\n",
      "   First time: 2025-08-31T13:51:05.975422\n",
      "   Last time: 2025-09-01T13:51:05.975422\n",
      "   Start time: 2025-08-31T13:51:05.975422\n",
      "   Last prediction time: 2025-09-01T13:51:05.975422\n",
      "   Expected end time: 2025-09-01T13:51:05.975422\n"
     ]
    }
   ],
   "source": [
    "# Debug the prediction length issue\n",
    "print(\"🔍 DEBUGGING PREDICTION LENGTH MISMATCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Expected time points: {time_horizon // time_increment}\")\n",
    "print(f\"Time horizon: {time_horizon} seconds\")\n",
    "print(f\"Time increment: {time_increment} seconds\")\n",
    "\n",
    "# Check one model's predictions in detail\n",
    "test_model = RandomWalkModel(volatility=0.02)\n",
    "test_predictions = test_model.predict(start_price, start_time, time_increment, time_horizon, 1)\n",
    "\n",
    "if test_predictions and test_predictions[0]:\n",
    "    print(f\"\\n📊 Test prediction details:\")\n",
    "    print(f\"   Number of simulations: {len(test_predictions)}\")\n",
    "    print(f\"   Number of time points: {len(test_predictions[0])}\")\n",
    "    print(f\"   First time: {test_predictions[0][0]['time']}\")\n",
    "    print(f\"   Last time: {test_predictions[0][-1]['time']}\")\n",
    "    \n",
    "    # Check if we're including the start time\n",
    "    start_time_iso = start_time.isoformat()\n",
    "    last_time_iso = test_predictions[0][-1]['time']\n",
    "    print(f\"   Start time: {start_time_iso}\")\n",
    "    print(f\"   Last prediction time: {last_time_iso}\")\n",
    "    \n",
    "    # Calculate expected end time\n",
    "    expected_end_time = start_time + timedelta(seconds=time_horizon)\n",
    "    print(f\"   Expected end time: {expected_end_time.isoformat()}\")\n",
    "else:\n",
    "    print(\"❌ No test predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832f6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 FIXING PREDICTION LENGTH MISMATCH\n",
      "============================================================\n",
      "Expected time points: 24\n",
      "Time horizon: 86400 seconds\n",
      "Time increment: 3600 seconds\n",
      "📊 Generating predictions for Random Walk...\n",
      "   ⚠️  Length mismatch: got 25, expected 24\n",
      "📊 Generating predictions for GBM...\n",
      "   ⚠️  Length mismatch: got 25, expected 24\n",
      "📊 Generating predictions for Mean Reversion...\n",
      "   ⚠️  Length mismatch: got 25, expected 24\n",
      "📊 Generating predictions for Fluid Dynamics...\n",
      "   ⚠️  Length mismatch: got 25, expected 24\n",
      "📊 Generating predictions for Ensemble (Equal)...\n",
      "   ✅ Generated 50 simulations, 24 time points each\n",
      "📊 Generating predictions for Ensemble (GBM-weighted)...\n",
      "   ✅ Generated 50 simulations, 24 time points each\n",
      "\n",
      "🎯 Successfully generated predictions for 2 models\n"
     ]
    }
   ],
   "source": [
    "# Fix the prediction generation to match expected time points\n",
    "print(\"🔧 FIXING PREDICTION LENGTH MISMATCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Recalculate with correct parameters\n",
    "start_price = 50000.0\n",
    "start_time = datetime.now()\n",
    "time_increment = 3600  # 1 hour\n",
    "time_horizon = 86400   # 24 hours\n",
    "num_simulations = 50\n",
    "\n",
    "# Calculate exact number of time points (excluding start time)\n",
    "num_time_points = time_horizon // time_increment\n",
    "print(f\"Expected time points: {num_time_points}\")\n",
    "print(f\"Time horizon: {time_horizon} seconds\")\n",
    "print(f\"Time increment: {time_increment} seconds\")\n",
    "\n",
    "# Generate predictions for all models with corrected approach\n",
    "all_predictions = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"📊 Generating predictions for {name}...\")\n",
    "    try:\n",
    "        # Generate predictions starting from start_time + time_increment\n",
    "        # This ensures we get exactly 24 predictions, not 25\n",
    "        predictions = model.predict(start_price, start_time, time_increment, time_horizon, num_simulations)\n",
    "        \n",
    "        # Verify the length is correct\n",
    "        if predictions and len(predictions) > 0:\n",
    "            first_sim_length = len(predictions[0])\n",
    "            if first_sim_length == num_time_points:\n",
    "                all_predictions[name] = predictions\n",
    "                print(f\"   ✅ Generated {len(predictions)} simulations, {first_sim_length} time points each\")\n",
    "            else:\n",
    "                print(f\"   ⚠️  Length mismatch: got {first_sim_length}, expected {num_time_points}\")\n",
    "        else:\n",
    "            print(f\"   ❌ No predictions generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 Successfully generated predictions for {len(all_predictions)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a6f3194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� FIXING ACTUAL DATA GENERATION\n",
      "============================================================\n",
      "✅ Generated 24 actual data points\n",
      "   First time: 2025-08-31T14:55:49.041141\n",
      "   Last time: 2025-09-01T13:55:49.041141\n",
      "   Expected: 24 points\n",
      "✅ Perfect alignment achieved!\n"
     ]
    }
   ],
   "source": [
    "# Fix actual data generation to match prediction length exactly\n",
    "print(\"�� FIXING ACTUAL DATA GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate actual data with exact same time points\n",
    "actual_times = []\n",
    "actual_prices = []\n",
    "\n",
    "current_time = start_time + timedelta(seconds=time_increment)  # Start from first prediction time\n",
    "\n",
    "for i in range(num_time_points):\n",
    "    actual_times.append(current_time)\n",
    "    # Generate realistic price movement\n",
    "    price_change = 0.001 * i + 0.02 * np.random.normal(0, 1)\n",
    "    price = start_price * (1 + price_change)\n",
    "    actual_prices.append(max(0.01, price))\n",
    "    \n",
    "    current_time += timedelta(seconds=time_increment)\n",
    "\n",
    "actual_data = [{'time': t.isoformat(), 'price': p} for t, p in zip(actual_times, actual_prices)]\n",
    "\n",
    "print(f\"✅ Generated {len(actual_data)} actual data points\")\n",
    "print(f\"   First time: {actual_data[0]['time']}\")\n",
    "print(f\"   Last time: {actual_data[-1]['time']}\")\n",
    "print(f\"   Expected: {num_time_points} points\")\n",
    "\n",
    "# Verify alignment\n",
    "if len(actual_data) == num_time_points:\n",
    "    print(\"✅ Perfect alignment achieved!\")\n",
    "else:\n",
    "    print(f\"❌ Still misaligned: {len(actual_data)} vs {num_time_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c83d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Re-calculating CRPS scores with fixed data...\n",
      "============================================================\n",
      "✅ Ensemble (Equal): CRPS = 854.04\n",
      "✅ Ensemble (GBM-weighted): CRPS = 873.94\n",
      "\n",
      "🏆 MODEL RANKING (Lower CRPS = Better):\n",
      "============================================================\n",
      " 1. Ensemble (Equal)          | CRPS:   854.04 | Horizon:  82800s | Sims:  50\n",
      " 2. Ensemble (GBM-weighted)   | CRPS:   873.94 | Horizon:  82800s | Sims:  50\n",
      "\n",
      "🥇 BEST PERFORMING MODEL: Ensemble (Equal)\n",
      "   CRPS Score: 854.04\n",
      "   This model would earn the most TAO rewards on Synth subnet!\n"
     ]
    }
   ],
   "source": [
    "# Re-calculate CRPS with fixed data\n",
    "print(\"📊 Re-calculating CRPS scores with fixed data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "crps_calculator = CRPSCalculator()\n",
    "model_performance = {}\n",
    "\n",
    "for name, predictions in all_predictions.items():\n",
    "    try:\n",
    "        # Verify prediction length before calculation\n",
    "        if predictions and len(predictions[0]) == len(actual_data):\n",
    "            metrics = crps_calculator.calculate_crps_for_synth(predictions, actual_data)\n",
    "            model_performance[name] = {\n",
    "                'crps_score': metrics['crps_score'],\n",
    "                'prediction_horizon': metrics['prediction_horizon'],\n",
    "                'num_simulations': len(predictions)\n",
    "            }\n",
    "            print(f\"✅ {name}: CRPS = {metrics['crps_score']:.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ {name}: Length mismatch - predictions: {len(predictions[0]) if predictions else 0}, actual: {len(actual_data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: Error calculating CRPS - {e}\")\n",
    "\n",
    "# Show results\n",
    "if model_performance:\n",
    "    ranked_models = sorted(model_performance.items(), key=lambda x: x[1]['crps_score'])\n",
    "    \n",
    "    print(f\"\\n🏆 MODEL RANKING (Lower CRPS = Better):\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (name, perf) in enumerate(ranked_models, 1):\n",
    "        print(f\"{i:2d}. {name:25s} | CRPS: {perf['crps_score']:8.2f} | \"\n",
    "              f\"Horizon: {perf['prediction_horizon']:6d}s | \"\n",
    "              f\"Sims: {perf['num_simulations']:3d}\")\n",
    "    \n",
    "    best_model = ranked_models[0]\n",
    "    print(f\"\\n🥇 BEST PERFORMING MODEL: {best_model[0]}\")\n",
    "    print(f\"   CRPS Score: {best_model[1]['crps_score']:.2f}\")\n",
    "    print(f\"   This model would earn the most TAO rewards on Synth subnet!\")\n",
    "else:\n",
    "    print(\"❌ No models successfully evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f6b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� DEBUGGING BASELINE MODELS\n",
      "============================================================\n",
      "\n",
      "📊 Testing Random Walk...\n",
      "   ✅ Success! Generated 1 simulations\n",
      "   First simulation has 2 time points\n",
      "   First prediction: {'time': '2025-08-31T13:57:39.882838', 'price': 49398.98411498816}\n",
      "\n",
      "📊 Testing GBM...\n",
      "   ✅ Success! Generated 1 simulations\n",
      "   First simulation has 2 time points\n",
      "   First prediction: {'time': '2025-08-31T13:57:39.882838', 'price': 49994.36142695105}\n",
      "\n",
      "📊 Testing Mean Reversion...\n",
      "   ✅ Success! Generated 1 simulations\n",
      "   First simulation has 2 time points\n",
      "   First prediction: {'time': '2025-08-31T13:57:39.882838', 'price': 50381.70902799521}\n"
     ]
    }
   ],
   "source": [
    "# Debug baseline models specifically\n",
    "print(\"�� DEBUGGING BASELINE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test each baseline model individually\n",
    "baseline_models = {\n",
    "    'Random Walk': RandomWalkModel(volatility=0.02),\n",
    "    'GBM': GeometricBrownianModel(drift=0.001, volatility=0.02),\n",
    "    'Mean Reversion': MeanReversionModel(mean_price=50000.0, reversion_strength=0.1, volatility=0.02)\n",
    "}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"\\n📊 Testing {name}...\")\n",
    "    try:\n",
    "        # Test with minimal parameters first\n",
    "        test_pred = model.predict(\n",
    "            start_price=50000.0,\n",
    "            start_time=datetime.now(),\n",
    "            time_increment=3600,\n",
    "            time_horizon=3600,  # Just 1 hour for testing\n",
    "            num_simulations=1\n",
    "        )\n",
    "        \n",
    "        if test_pred:\n",
    "            print(f\"   ✅ Success! Generated {len(test_pred)} simulations\")\n",
    "            print(f\"   First simulation has {len(test_pred[0])} time points\")\n",
    "            print(f\"   First prediction: {test_pred[0][0] if test_pred[0] else 'None'}\")\n",
    "        else:\n",
    "            print(f\"   ❌ No predictions returned\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f050aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CHECKING MODEL METHOD SIGNATURES\n",
      "============================================================\n",
      "\n",
      "📋 Random Walk:\n",
      "   Type: <class 'models.baseline.random_walk.RandomWalkModel'>\n",
      "   Predict method signature: (start_price: float, start_time: datetime.datetime, time_increment: int = 300, time_horizon: int = 86400, num_simulations: int = 100) -> List[List[Dict[str, Any]]]\n",
      "   Expected params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   Actual params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   ✅ Parameter match!\n",
      "\n",
      "📋 GBM:\n",
      "   Type: <class 'models.baseline.geometric_brownian.GeometricBrownianModel'>\n",
      "   Predict method signature: (start_price: float, start_time: datetime.datetime, time_increment: int = 300, time_horizon: int = 86400, num_simulations: int = 100) -> List[List[Dict[str, Any]]]\n",
      "   Expected params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   Actual params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   ✅ Parameter match!\n",
      "\n",
      "📋 Mean Reversion:\n",
      "   Type: <class 'models.baseline.mean_reversion.MeanReversionModel'>\n",
      "   Predict method signature: (start_price: float, start_time: datetime.datetime, time_increment: int = 300, time_horizon: int = 86400, num_simulations: int = 100) -> List[List[Dict[str, Any]]]\n",
      "   Expected params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   Actual params: ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
      "   ✅ Parameter match!\n"
     ]
    }
   ],
   "source": [
    "# Check the method signatures of baseline models\n",
    "print(\"🔍 CHECKING MODEL METHOD SIGNATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"\\n📋 {name}:\")\n",
    "    print(f\"   Type: {type(model)}\")\n",
    "    \n",
    "    # Check if predict method exists\n",
    "    if hasattr(model, 'predict'):\n",
    "        import inspect\n",
    "        sig = inspect.signature(model.predict)\n",
    "        print(f\"   Predict method signature: {sig}\")\n",
    "        \n",
    "        # Check if it matches what we're calling\n",
    "        expected_params = ['start_price', 'start_time', 'time_increment', 'time_horizon', 'num_simulations']\n",
    "        actual_params = list(sig.parameters.keys())\n",
    "        print(f\"   Expected params: {expected_params}\")\n",
    "        print(f\"   Actual params: {actual_params}\")\n",
    "        \n",
    "        if actual_params == expected_params:\n",
    "            print(\"   ✅ Parameter match!\")\n",
    "        else:\n",
    "            print(\"   ❌ Parameter mismatch!\")\n",
    "    else:\n",
    "        print(\"   ❌ No predict method found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ddc1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "�� FIXING ACTUAL DATA GENERATION TO MATCH BASELINE MODELS\n",
      "============================================================\n",
      "Expected time points (including start): 25\n",
      "Time horizon: 86400 seconds\n",
      "Time increment: 3600 seconds\n",
      "✅ Generated 25 actual data points\n",
      "   First time: 2025-08-31T13:55:49.041141\n",
      "   Last time: 2025-09-01T13:55:49.041141\n",
      "   Expected: 25 points\n",
      "✅ Perfect alignment achieved!\n"
     ]
    }
   ],
   "source": [
    "# Fix actual data generation to match baseline model behavior\n",
    "print(\"�� FIXING ACTUAL DATA GENERATION TO MATCH BASELINE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Baseline models include start time + future predictions\n",
    "# So we need num_time_points + 1 total points\n",
    "num_time_points = (time_horizon // time_increment) + 1\n",
    "print(f\"Expected time points (including start): {num_time_points}\")\n",
    "print(f\"Time horizon: {time_horizon} seconds\")\n",
    "print(f\"Time increment: {time_increment} seconds\")\n",
    "\n",
    "# Generate actual data starting from start_time (including start)\n",
    "actual_times = []\n",
    "actual_prices = []\n",
    "\n",
    "current_time = start_time  # Start from the actual start time\n",
    "\n",
    "for i in range(num_time_points):\n",
    "    actual_times.append(current_time)\n",
    "    \n",
    "    if i == 0:\n",
    "        # Start price\n",
    "        actual_prices.append(start_price)\n",
    "    else:\n",
    "        # Generate realistic price movement for future times\n",
    "        price_change = 0.001 * i + 0.02 * np.random.normal(0, 1)\n",
    "        price = start_price * (1 + price_change)\n",
    "        actual_prices.append(max(0.01, price))\n",
    "    \n",
    "    current_time += timedelta(seconds=time_increment)\n",
    "\n",
    "actual_data = [{'time': t.isoformat(), 'price': p} for t, p in zip(actual_times, actual_prices)]\n",
    "\n",
    "print(f\"✅ Generated {len(actual_data)} actual data points\")\n",
    "print(f\"   First time: {actual_data[0]['time']}\")\n",
    "print(f\"   Last time: {actual_data[-1]['time']}\")\n",
    "print(f\"   Expected: {num_time_points} points\")\n",
    "\n",
    "# Verify alignment\n",
    "if len(actual_data) == num_time_points:\n",
    "    print(\"✅ Perfect alignment achieved!\")\n",
    "else:\n",
    "    print(f\"❌ Still misaligned: {len(actual_data)} vs {num_time_points}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e01341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 REGENERATING PREDICTIONS WITH CORRECT PARAMETERS\n",
      "============================================================\n",
      "📊 Generating predictions for Random Walk...\n",
      "   ✅ Generated 50 simulations, 25 time points each\n",
      "📊 Generating predictions for GBM...\n",
      "   ✅ Generated 50 simulations, 25 time points each\n",
      "📊 Generating predictions for Mean Reversion...\n",
      "   ✅ Generated 50 simulations, 25 time points each\n",
      "📊 Generating predictions for Fluid Dynamics...\n",
      "   ✅ Generated 50 simulations, 25 time points each\n",
      "📊 Generating predictions for Ensemble (Equal)...\n",
      "   ⚠️  Length mismatch: got 24, expected 25\n",
      "📊 Generating predictions for Ensemble (GBM-weighted)...\n",
      "   ⚠️  Length mismatch: got 24, expected 25\n",
      "\n",
      "🎯 Successfully generated predictions for 4 models\n"
     ]
    }
   ],
   "source": [
    "# Regenerate predictions with correct understanding\n",
    "print(\"📊 REGENERATING PREDICTIONS WITH CORRECT PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate predictions for all models\n",
    "all_predictions = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"📊 Generating predictions for {name}...\")\n",
    "    try:\n",
    "        predictions = model.predict(start_price, start_time, time_increment, time_horizon, num_simulations)\n",
    "        \n",
    "        # Verify the length is correct\n",
    "        if predictions and len(predictions) > 0:\n",
    "            first_sim_length = len(predictions[0])\n",
    "            if first_sim_length == num_time_points:\n",
    "                all_predictions[name] = predictions\n",
    "                print(f\"   ✅ Generated {len(predictions)} simulations, {first_sim_length} time points each\")\n",
    "            else:\n",
    "                print(f\"   ⚠️  Length mismatch: got {first_sim_length}, expected {num_time_points}\")\n",
    "        else:\n",
    "            print(f\"   ❌ No predictions generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "print(f\"\\n🎯 Successfully generated predictions for {len(all_predictions)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db1af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Re-calculating CRPS scores with corrected data...\n",
      "============================================================\n",
      "✅ Random Walk: CRPS = 927.30\n",
      "✅ GBM: CRPS = 1028.66\n",
      "✅ Mean Reversion: CRPS = 757.07\n",
      "✅ Fluid Dynamics: CRPS = 885.07\n",
      "\n",
      "🏆 MODEL RANKING (Lower CRPS = Better):\n",
      "============================================================\n",
      " 1. Mean Reversion            | CRPS:   757.07 | Horizon:  86400s | Sims:  50\n",
      " 2. Fluid Dynamics            | CRPS:   885.07 | Horizon:  86400s | Sims:  50\n",
      " 3. Random Walk               | CRPS:   927.30 | Horizon:  86400s | Sims:  50\n",
      " 4. GBM                       | CRPS:  1028.66 | Horizon:  86400s | Sims:  50\n",
      "\n",
      "🥇 BEST PERFORMING MODEL: Mean Reversion\n",
      "   CRPS Score: 757.07\n",
      "   This model would earn the most TAO rewards on Synth subnet!\n"
     ]
    }
   ],
   "source": [
    "# Re-calculate CRPS with corrected data\n",
    "print(\"📊 Re-calculating CRPS scores with corrected data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "crps_calculator = CRPSCalculator()\n",
    "model_performance = {}\n",
    "\n",
    "for name, predictions in all_predictions.items():\n",
    "    try:\n",
    "        # Verify prediction length before calculation\n",
    "        if predictions and len(predictions[0]) == len(actual_data):\n",
    "            metrics = crps_calculator.calculate_crps_for_synth(predictions, actual_data)\n",
    "            model_performance[name] = {\n",
    "                'crps_score': metrics['crps_score'],\n",
    "                'prediction_horizon': metrics['prediction_horizon'],\n",
    "                'num_simulations': len(predictions)\n",
    "            }\n",
    "            print(f\"✅ {name}: CRPS = {metrics['crps_score']:.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ {name}: Length mismatch - predictions: {len(predictions[0]) if predictions else 0}, actual: {len(actual_data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ {name}: Error calculating CRPS - {e}\")\n",
    "\n",
    "# Show results\n",
    "if model_performance:\n",
    "    ranked_models = sorted(model_performance.items(), key=lambda x: x[1]['crps_score'])\n",
    "    \n",
    "    print(f\"\\n🏆 MODEL RANKING (Lower CRPS = Better):\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, (name, perf) in enumerate(ranked_models, 1):\n",
    "        print(f\"{i:2d}. {name:25s} | CRPS: {perf['crps_score']:8.2f} | \"\n",
    "              f\"Horizon: {perf['prediction_horizon']:6d}s | \"\n",
    "              f\"Sims: {perf['num_simulations']:3d}\")\n",
    "    \n",
    "    best_model = ranked_models[0]\n",
    "    print(f\"\\n🥇 BEST PERFORMING MODEL: {best_model[0]}\")\n",
    "    print(f\"   CRPS Score: {best_model[1]['crps_score']:.2f}\")\n",
    "    print(f\"   This model would earn the most TAO rewards on Synth subnet!\")\n",
    "else:\n",
    "    print(\"❌ No models successfully evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e62ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
